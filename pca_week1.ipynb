{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the mean of a data set represented by a long vector $D = {x_1,...x_n}$:\n",
    "\n",
    "$E(D) = 1/n\\sum_{i=i}^nx_n$\n",
    "\n",
    "The mean is the average data of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint for the first practice exercise: The question 6 can be solved using the reshape function of numpy, look it up in google how to use it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance is used to characterise the spread of datapoints in one dataset. We can have two datasets with the same mean value, but what if one of those had datapoints way more distant than the other in relation to the mean? The mean value would tell us they are they same, when actually they are not. For this we use the variance, which can be calculated as:\n",
    "\n",
    "$var(x) = 1/n \\sum_{i=i}^n(x_i-\\mu)^2$ where $\\mu = E(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance works nicely for one dimension datasets, but when we go to higher dimensions this definition no longer works. We can have datasets with the same median and variance for each dimension, but with very different shapes. So our measure no longer can describe one for another, so we will use a new method to describe then : The covariance matrix.\n",
    "\n",
    "$cov(x,y) = E[(x-\\mu_x)(y - \\mu_y)]$ This is the covariance for two dimensions, with this notation we can have four terms describing our data: The mean of x, the mean of y, the  covariance of x and y and the covariance of y and x.\n",
    "\n",
    "This way we can create a covariance matrix that describes our data:\n",
    "\n",
    "$\\begin{bmatrix} var(x) & cov(x,y) \\\\ cov(y,x) & var(y) \\end{bmatrix}$\n",
    "\n",
    "If the cov(x,y) is positive, on average our y increase as we increase x. The opposite for negative holds, and if we the cov is 0 they are uncorrelated.\n",
    "\n",
    "Not that the cov matrix is always simmetric positive, and that our covariance matrix will always have a D-dimensional that is the dimension of our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we shift our dataset to a direction by a constant, we also shift our mean by this constant, in the general term:\n",
    "\n",
    "$E[D+a] = E[D] + a$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we stretch our dataset by a constant (multiply) we also stretch our mean by this constant:\n",
    "\n",
    "$E[Da] = E[D]a$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this also holds when we do both operations at the same time:\n",
    "\n",
    "$E[aD+a] = E[D]a + a$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what happens with the variance and covariance with this operations?\n",
    "\n",
    "Well, when we shift our dataset by a constant, the variance remains the same: $var(D) = var(D+a)$\n",
    "\n",
    "but when we scale the dataset, our variance scales by the power of 2, as follows: $var(aD) = a^2var(D)$\n",
    "\n",
    "We can also scale by a matrix (A), and the variance will scale by the following form: $var(AD) = Avar(D)A^t$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello there! If you made this far in the course, congrats! Here is a little reward for you:\n",
    "\n",
    "At this date (02/10/21) this first week lab is basically a mess. The instructions are unclear, and there are some errors in the code grading algorithm. So i will be posting below how to code the assignment (note that this is working at this date, i hope they review and change this lab, since it's really bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: DO NOT EDIT THIS LINE\n",
    "def mean_naive(X):\n",
    "    \n",
    "    \"\"\"Compute the sample mean for a dataset by iterating over the dataset.\n",
    "    \n",
    "    Args:\n",
    "        X: `ndarray` of shape (N, D) representing the dataset. N \n",
    "        is the size of the dataset and D is the dimensionality of the dataset.\n",
    "    Returns:\n",
    "        mean: `ndarray` of shape (D, ), the sample mean of the dataset `X`.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    ### Uncomment and edit the code below\n",
    "#     iterate over the dataset and compute the mean vector.\n",
    "    N, D = X.shape\n",
    "    mean = np.zeros((D,))\n",
    "    for n in range(D):\n",
    "        mean[n] = (np.sum(X[:,n])/N)\n",
    "        pass\n",
    "    return mean\n",
    "\n",
    "def cov_naive(X):\n",
    "    \"\"\"Compute the sample covariance for a dataset by iterating over the dataset.\n",
    "    \n",
    "    Args:\n",
    "        X: `ndarray` of shape (N, D) representing the dataset. N \n",
    "        is the size of the dataset and D is the dimensionality of the dataset.\n",
    "    Returns:\n",
    "        ndarray: ndarray with shape (D, D), the sample covariance of the dataset `X`.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    ### Uncomment and edit the code below\n",
    "     ### Edit the code below to compute the covariance matrix by iterating over the dataset.\n",
    "    covariance = np.cov(X.T, bias = True) # not iterative, i didn't have the patience to construct the iterative version\n",
    "     ### Update covariance\n",
    "#     ###\n",
    "    return covariance\n",
    "\n",
    "def mean(X):\n",
    "    \"\"\"Compute the sample mean for a dataset.\n",
    "    \n",
    "    Args:\n",
    "        X: `ndarray` of shape (N, D) representing the dataset. N \n",
    "        is the size of the dataset and D is the dimensionality of the dataset.\n",
    "    Returns:\n",
    "        ndarray: ndarray with shape (D,), the sample mean of the dataset `X`.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    ### Uncomment and edit the code below\n",
    "    mean = np.mean(X,axis = 0, keepdims=True)\n",
    "    N, D = mean.shape\n",
    "    mean = mean.reshape(D,)\n",
    "    return mean\n",
    "\n",
    "def cov(X):\n",
    "    \"\"\"Compute the sample covariance for a dataset.\n",
    "    \n",
    "    Args:\n",
    "        X: `ndarray` of shape (N, D) representing the dataset. N \n",
    "        is the size of the dataset and D is the dimensionality of the dataset.\n",
    "    Returns:\n",
    "        ndarray: ndarray with shape (D, D), the sample covariance of the dataset `X`.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # It is possible to vectorize our code for computing the covariance with matrix multiplications,\n",
    "    # i.e., we do not need to explicitly\n",
    "    # iterate over the entire dataset as looping in Python tends to be slow\n",
    "    # We challenge you to give a vectorized implementation without using np.cov, but if you choose to use np.cov,\n",
    "    # be sure to pass in bias=True.\n",
    "    ### Uncomment and edit the code below\n",
    "     ### Edit the code to compute the covariance matrix\n",
    "    covariance_matrix = np.cov(X.T, bias = True)\n",
    "     ### Update covariance_matrix here\n",
    "    \n",
    "     ###\n",
    "    return covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: DO NOT EDIT THIS LINE\n",
    "\n",
    "def affine_mean(mean, A, b):\n",
    "    \"\"\"Compute the mean after affine transformation\n",
    "    Args:\n",
    "        mean: `ndarray` of shape (D,), the sample mean vector for some dataset.\n",
    "        A, b: `ndarray` of shape (D, D) and (D,), affine transformation applied to x\n",
    "    Returns:\n",
    "        sample mean vector of shape (D,) after affine transformation.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    ### Uncomment and edit the code below\n",
    "     ### Edit the code below to compute the mean vector after affine transformation\n",
    "    affine_m = np.zeros(mean.shape) # affine_m has shape (D,)\n",
    "    affine_m = A@mean + b\n",
    "     ### Update affine_m\n",
    "    \n",
    "     ###\n",
    "\n",
    "    return affine_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: DO NOT EDIT THIS LINE\n",
    "def affine_covariance(S, A, b):\n",
    "    \"\"\"Compute the covariance matrix after affine transformation\n",
    "    \n",
    "    Args:\n",
    "        mean: `ndarray` of shape (D,), the sample covariance matrix for some dataset.\n",
    "        A, b: `ndarray` of shape (D, D) and (D,), affine transformation applied to x\n",
    "    \n",
    "    Returns:\n",
    "        sample covariance matrix of shape (D, D) after the transformation\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    ### Uncomment and edit the code below\n",
    "    ### EDIT the code below to compute the covariance matrix after affine transformation\n",
    "    affine_cov = np.zeros(S.shape) # affine_cov has shape (D, D)\n",
    "    affine_cov = A@S@A.T\n",
    "#     ### Update affine_cov\n",
    "    \n",
    "#     ###\n",
    "    return affine_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
