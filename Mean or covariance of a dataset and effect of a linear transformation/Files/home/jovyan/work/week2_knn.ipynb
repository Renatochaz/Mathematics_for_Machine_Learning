{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors\n",
    "\n",
    "In this section, we will explore the [KNN classification algorithm](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm).\n",
    "A classification algorithm takes input some data and use the data to \n",
    "determine which class (category) this piece of data belongs to.\n",
    "\n",
    "![flower](https://archive.ics.uci.edu/ml/assets/MLimages/Large53.jpg)\n",
    "\n",
    "As a motivating example, consider the [iris flower dataset](https://archive.ics.uci.edu/ml/datasets/iris). The dataset consists\n",
    "of 150 data points where each data point is a feature vector $\\boldsymbol x \\in \\mathbb{R}^4$ describing the attribute of a flower in the dataset, the four dimensions represent \n",
    "\n",
    "1. sepal length in cm \n",
    "2. sepal width in cm \n",
    "3. petal length in cm \n",
    "4. petal width in cm \n",
    "\n",
    "\n",
    "and the corresponding target $y \\in \\mathbb{Z}$ describes the class of the flower. It uses the integers $0$, $1$ and $2$ to represent the 3 classes of flowers in this dataset.\n",
    "\n",
    "0. Iris Setosa\n",
    "1. Iris Versicolour \n",
    "2. Iris Virginica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PACKAGE: DO NOT EDIT THIS CELL\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from ipywidgets import interact\n",
    "from load_data import load_mnist\n",
    "\n",
    "# Plot figures so that they can be shown in the notebook\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors, datasets\n",
    "iris = datasets.load_iris()\n",
    "print('data shape is {}'.format(iris.data.shape))\n",
    "print('class shape is {}'.format(iris.target.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the simplicity of the exercise, we will only use the first 2 dimensions (sepal length and sepal width) of as features used to classify the flowers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[:, :2] # use first two version for simplicity\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a scatter plot of the dataset below. The x and y axis represent the sepal length and sepal width of the dataset, and the color of the points represent the different classes of flowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets\n",
    "iris = datasets.load_iris()\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000',  '#00FF00', '#0000FF'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "for i, iris_class in enumerate(['Iris Setosa', 'Iris Versicolour', 'Iris Virginica']):\n",
    "    idx = y==i\n",
    "    ax.scatter(X[idx,0], X[idx,1], \n",
    "               c=cmap_bold.colors[i], edgecolor='k', \n",
    "               s=20, label=iris_class);\n",
    "ax.set(xlabel='sepal length (cm)', ylabel='sepal width (cm)')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea behind a KNN classifier is pretty simple: Given a training set $\\boldsymbol X \\in \\mathbb{R}^{N \\times D}$ and $\\boldsymbol y \\in \\mathbb{Z}^N$, we predict the label of a new point $\\boldsymbol x \\in \\mathbb{R}^{D}$ __as the label of the majority of its \"K nearest neighbor\"__ (hence the name KNN) by some distance measure (e.g the Euclidean distance).\n",
    "Here, $N$ is the number of data points in the dataset, and $D$ is the dimensionality of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise distances\n",
    "We will implement a function `pairwise_distance_matrix` for computing \n",
    "the pairwise distances between two datasets $\\boldsymbol X$ and $\\boldsymbol Y$.\n",
    "We can then use this pairwise distance matrix to find out the K-nearest neighbors for each row in $\\boldsymbol Y$ given $\\boldsymbol X$.\n",
    "\n",
    "You may be tempting to iterate through\n",
    "rows of $\\boldsymbol X$ and $\\boldsymbol Y$ and fill in the distance matrix, but that is slow! Can you\n",
    "think of some way to vectorize your computation (i.e. make it faster by using numpy/scipy operations only)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-42d92e38085880f0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: DO NOT EDIT THIS LINE\n",
    "\n",
    "def pairwise_distance_matrix(X, Y):\n",
    "    \"\"\"Compute the pairwise distance between rows of X and rows of Y\n",
    "\n",
    "    Arguments\n",
    "    ----------\n",
    "    X: ndarray of size (N, D)\n",
    "    Y: ndarray of size (M, D)\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    D: matrix of shape (N, M), each entry D[i,j] is the distance between\n",
    "    X[i] and Y[j] using the dot product.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    ### Uncomment and modify the code below\n",
    "#     N, D = X.shape\n",
    "#     M, _ = Y.shape\n",
    "#     distance_matrix = np.zeros((N, M)) # <-- EDIT THIS to compute the correct distance matrix.\n",
    "#     return distance_matrix    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-46b53eb0aa0995d1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test cases for computing pairwise distance matrix.\n",
    "\n",
    "X_test = np.array([[2., 1],\n",
    "              [1, 2]])\n",
    "\n",
    "Y_test = np.array([[0., 1], [1, 1]])\n",
    "\n",
    "np.testing.assert_allclose(\n",
    "    pairwise_distance_matrix(X_test, X_test),\n",
    "    np.array([[0.        , 1.41421356],\n",
    "              [1.41421356, 0.        ]]))\n",
    "\n",
    "np.testing.assert_allclose(\n",
    "    pairwise_distance_matrix(X_test, Y_test),\n",
    "    np.array([[2.        , 1.        ],\n",
    "              [1.41421356, 1.        ]])\n",
    ")\n",
    "\n",
    "np.testing.assert_allclose(\n",
    "    pairwise_distance_matrix(Y_test, X_test).T,\n",
    "    np.array([[2.        , 1.        ],\n",
    "              [1.41421356, 1.        ]])\n",
    ")\n",
    "\n",
    "### Some hidden tests below\n",
    "### ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN\n",
    "Given the `pairwise_distance_matrix` definition above, we are now ready to implement\n",
    "KNN. We have provided the implementation for you, but do have a look at the code\n",
    "to get a better understanding of what it does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a7c6b80357be6f31",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the \"decision boundary\" of the KNN classifier, which is the region of a problem space in which the output label of a classifier is ambiguous. This would help us develop an intuition of how KNN behaves in practice. The code below plots the decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "step = 0.1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, step),\n",
    "                     np.arange(y_min, y_max, step))\n",
    "\n",
    "ypred = []\n",
    "for xtest in np.array([xx.ravel(), yy.ravel()]).T:\n",
    "    ypred.append(KNN(K, X, y, xtest))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "\n",
    "ax.pcolormesh(xx, yy, np.array(ypred).reshape(xx.shape), cmap=cmap_light)\n",
    "ax.scatter(X[:,0], X[:,1], c=y, cmap=cmap_bold, edgecolor='k', s=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "mathematics-machine-learning-pca",
   "graded_item_id": "kGOjp",
   "launcher_item_id": "Myc4L"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
